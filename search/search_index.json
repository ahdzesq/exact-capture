{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Exact Capture is a high-rate, lossless packet capture solution for ExaNIC network adapters. The system is fully open source and designed for performance as well as ease of configuration. It can be used with any ExaNIC network adapter, and is optimised for use with ExaDISK high speed NVMe SSDs. The system can be deployed on any suitably powerful server system. This manual covers full details on configuring and operating Exact Capture including: Quick start guide Installing and building Hardware requirements Configuration options Version history","title":"Introduction"},{"location":"arch/","text":"The Exact Capture software system comprises 4 major internal components: One or more \u201chot\u201d threads - to read packets from the ExaNIC(s) into memory One or more \u201ccold\u201d threads - to write packets from memory to disk(s) One or more shared memory queues - to connect the hot and cold threads to each other One management thread - responsible for control and statistics collection / reporting These basic architectural components are illustrated below, with the addition of the ExaNIC and ExaDisk resources. The head of each column highlights the performance limiting resource for that component: This page was last updated on .","title":"Internal Architecture"},{"location":"config/","text":"The Exact Capture application supports a number of configuration options in both short and long form. For example: $ exact-capture -i exanic0:0 --log-report-int 10 .... A quick start guide is available for getting started. The following table lists all commands available: Short Long Default Description i input (required) The ExaNIC interface(s) to capture on o output (required) The destination directory and filename stub to output to. Filenames will be output in the following format /output/dir/base_xx.expcap. Where xx is a unique file index. For details on the expcap format please see the Exact Capture Output Format (expcap) section later in this document. c cpus (required) The list of CPUs to assign threads to for management, listening and writing threads. This is specified in the the following format, m:ls,ls,ls:ws,ws,ws . Where m is the core number for management, and ls/ws are comma separated lists of listener and writer CPU core numbers. For example --cpus=5:2,3:7,6,1 would configure Exact Capture to run the management thread on CPU 5, with two NIC listener threads on on CPUs 2 and 3 respectively, and three (or more) disk writer threads on cores 1,6 & 7 respectively. Note: the number of listener CPUs must be exactly equal to the number of ExaNIC --interfaces in use. Furthermore listener threads cannot share CPUs with management or writer threads. If there are fewer writer threads than --outputs , writer threads will be reused. k no-kernel (flag) Prevents packets from reaching the kernel, by disabling interrupt generation for packets arriving on the ports used by exact-capture. It is recommended to always enable this option, to ensure the best performance from exact-capture. s snaplen 2048B In some cases it is not necessary / useful to capture the entire packet. Set the snap length to determine the maximum size of packet that can be captured. This value cannot be 0 or less. m maxfile 0 (unlimited) High rate capture can produce very large file sizes. To reduce the file sizes, Exact Capture can cap the file size to a maximum, and will start a new file each time it is reached. A value of 0 or less puts no limit on the output file size. l logfile (none) Exact capture can optionally write log messages to a log file specified. t log-report-int 1.0 This sets the statistics calculation and logging interval in seconds. v verbose (flag) Enabling verbose mode will produce 2 output log lines every log interval (see above). These log lines will include summary statistics of the performance of all listener threads and all writer threads. V more-verbose (flag) Enabling more verbose mode will produce 1 output log line for every listener and writer thread. Each log line will include per-thread statistics counters/statistics. This can be combined with --verbose mode above. d debug-logging (flag) Debug logging mode enables display of the full file path, process ID and thread ID in each output log line. This is useful to track where a given log message originated. T no-log-ts (flag) By default, logs include a timestamp. This can make the output overly verbose. Use this flag to disable timestamps. w no-warn-overflow (flag) Software overflows will produce a warning. This may be problematic if the system is underperforming and these happen often. The flag disables these warnings. S no-spin (flag) By default Exact Capture outputs a progress \u201cspinner\u201d to the console. This flag disables it. n no-promisc (flag) By default Exact Capture puts the NIC into promiscuous mode. This flag disables it. p perf-test (flag) Exact Capture supports several performance testing modes. These can be used to give a sense of the best possible performance that you can expect from your system configuration. The modes are as follows: No performance testing Replace all ExaNIC interfaces with a dummy interface. ExaNICs are no longer a performance limitation. This tests the maximum possible receive rate that your system can achieve for 64B frames. Note that 10GbE line-rate with 64B frames is about 7Gb/s (due to Ethernet interfame gap overheads). Replace the internal memory queue with a dummy interface on both sides. This tests the maximum performance possible when when system memory is not the bottleneck. This is also a good test of disk writing speed (for minimum sized packets). Replace the ExaDisk interface with a dummy. This tests the performance through the system when disk writing speed is not a limitation. This may be helpful to debug cases where your disks are not configured/performing correctly. Replace both the ExaNIC and the internal memory ring with dummies. Can be used to measure the absolute best performance possible when NICs and memory are not the limitations. Can also help to find interference bugs between ExaNICs and ExaDisks sharing limited PCIe bandwidth. Replace the ExaNIC and ExaDisk with dummies. This is useful for testing the maximum achievable application throughput, including through system memory, but excluding reading from and writing to real hardware. Replace the memory queues and ExaDisk with dummies. Can be help to find interference bugs between ExaNICs and ExaDisks sharing limited PCIe bandwidth. Replace the ExaNIC, memory queue and ExaDisk interfaces with dummies. Useful for determining the overheads within the application (i.e. CPU speed) issues.","title":"Configuration Guide"},{"location":"expcap/","text":"Exact Capture outputs packet captures to a modified pcap format called expcap . The expcap format is a backwards compatible extension to standard pcap format. A number of tools and utilities are included for operating on these files and converting them into standard pcap format if necessary. For reference, standard pcap files are formatted as follows (more details can be found on the Wireshark website): Padding Packets As a performance optimisation, Exact Capture occasionally needs to insert padding packets (e.g. to align to a 4k boundary) into the output file. These packets are easily recognizable because pcap header wire length field (as above) is set to 0B, with the on disk length field (again as above) is set to the size of the padding. Although setting these header fields precisely captures the semantics of the padding packets (i.e bytes written to disk that were never found on the wire), this is technically a pcap file specification violation. Presumably the writers never envisaged this kind of use case. Nevertheless, standard tools like Wireshark operate correctly and ignore these packets as they should. The following figure depicts a padding packet directly after the file header. This will be found in all Exact Capture output files. Packet Footers Each captured packet is extended with a packet footer. This footer contains a variety of extra fields, not available in the standard pcap format. When the footer is added, the standard pcap disk bytes field is updated to reflect the extra length on disk. Once again, this means that the byes on disk value may exceed the bytes on the wire value (though not always. e.g. when a snaplength is set). The addition of a footer adds bytes to the disk that were never found on the wire is again, technically a PCAP specification violation. However, once again, standard pcap processing tools like Wireshark operate correctly and ignore these extra bytes as they should. The above figure shows a representation of expcap packet footers added to the first packet. The additional expcap footer fields are described in detail in the table below. They borrow the spirit of some of the fields found in the ERF format. Field Width (bits) Description Time (seconds) 32 Time in seconds since the epoch Time (picoseconds) 40 Time in picoseconds since the last second boundary Flags 8 The following flags bits are currently supported: New CRC Calculated (The CRC field contains a new new value including the footer) Frame aborted - this frame was aborted on the wire by the sender. Frame corrupt - the hardware CRC checker detected an error with this frame. Frame truncated - this packet was longer than the snap length and has been truncated. Device ID Number 8 The ID of the device that captured these packets. For example, when capturing on the exanic3:7 interface, the device number would be 3. Port ID Number 8 The port on the device that was used to capture the packet. For example, capturing on exanic3:7 interface, the port number would be 7. CRC top 16 If the new CRC flag is not set, contains the number of packets dropped between this packet and the previous packet. Otherwise this is the top 16 bits of the new CRC. CRC bottom 16 If the new CRC flag is set, contains the bottom 16 bits of the new CRC. Otherwise, unused.","title":"Output Format (expcap)"},{"location":"expcap/#padding-packets","text":"As a performance optimisation, Exact Capture occasionally needs to insert padding packets (e.g. to align to a 4k boundary) into the output file. These packets are easily recognizable because pcap header wire length field (as above) is set to 0B, with the on disk length field (again as above) is set to the size of the padding. Although setting these header fields precisely captures the semantics of the padding packets (i.e bytes written to disk that were never found on the wire), this is technically a pcap file specification violation. Presumably the writers never envisaged this kind of use case. Nevertheless, standard tools like Wireshark operate correctly and ignore these packets as they should. The following figure depicts a padding packet directly after the file header. This will be found in all Exact Capture output files.","title":"Padding Packets"},{"location":"expcap/#packet-footers","text":"Each captured packet is extended with a packet footer. This footer contains a variety of extra fields, not available in the standard pcap format. When the footer is added, the standard pcap disk bytes field is updated to reflect the extra length on disk. Once again, this means that the byes on disk value may exceed the bytes on the wire value (though not always. e.g. when a snaplength is set). The addition of a footer adds bytes to the disk that were never found on the wire is again, technically a PCAP specification violation. However, once again, standard pcap processing tools like Wireshark operate correctly and ignore these extra bytes as they should. The above figure shows a representation of expcap packet footers added to the first packet. The additional expcap footer fields are described in detail in the table below. They borrow the spirit of some of the fields found in the ERF format. Field Width (bits) Description Time (seconds) 32 Time in seconds since the epoch Time (picoseconds) 40 Time in picoseconds since the last second boundary Flags 8 The following flags bits are currently supported: New CRC Calculated (The CRC field contains a new new value including the footer) Frame aborted - this frame was aborted on the wire by the sender. Frame corrupt - the hardware CRC checker detected an error with this frame. Frame truncated - this packet was longer than the snap length and has been truncated. Device ID Number 8 The ID of the device that captured these packets. For example, when capturing on the exanic3:7 interface, the device number would be 3. Port ID Number 8 The port on the device that was used to capture the packet. For example, capturing on exanic3:7 interface, the port number would be 7. CRC top 16 If the new CRC flag is not set, contains the number of packets dropped between this packet and the previous packet. Otherwise this is the top 16 bits of the new CRC. CRC bottom 16 If the new CRC flag is set, contains the bottom 16 bits of the new CRC. Otherwise, unused.","title":"Packet Footers"},{"location":"install/","text":"Source Code and Licensing Exact Capture is available from github.com as an open source project. If you would like to discuss alternative licensing schemes, please contact the Exablaze sales team. Hardware Requirements Exact Capture requires a high performance server to operate optimally. Please read the Server Requirements for more details. Software Requirements To build the software, you will need a recent C compiler supporting C99 or higher, and to have installed the ExaNIC software libraries (also available from github.com). Building There are 3 build options for Exact Capture: Performance build Error assertions build Debug build By default, Exact Capture is built in performance mode. In performance mode, unnecessary internal error checking is disabled. For example, bounds checks on memory access. To build Exact Capture in performance mode, simply run make in the top level. To build a version with stricter internal error checking assertions, run make assert . This version is still capable of operating at 10Gb/s on many systems, though will suffer marginal performance degradation, especially on slower CPUs. To build a debug version, run make debug . The debug build applies stricter warning checking requirements at build time, and enables detailed debug tracing throughout the application. This version is unlikely to keep up at high-rate. (un)Installation To install Exact Capture, run make install as the root user. To uninstall, run make uninstall as the root user.","title":"Installation"},{"location":"install/#source-code-and-licensing","text":"Exact Capture is available from github.com as an open source project. If you would like to discuss alternative licensing schemes, please contact the Exablaze sales team.","title":"Source Code and Licensing"},{"location":"install/#hardware-requirements","text":"Exact Capture requires a high performance server to operate optimally. Please read the Server Requirements for more details.","title":"Hardware Requirements"},{"location":"install/#software-requirements","text":"To build the software, you will need a recent C compiler supporting C99 or higher, and to have installed the ExaNIC software libraries (also available from github.com).","title":"Software Requirements"},{"location":"install/#building","text":"There are 3 build options for Exact Capture: Performance build Error assertions build Debug build By default, Exact Capture is built in performance mode. In performance mode, unnecessary internal error checking is disabled. For example, bounds checks on memory access. To build Exact Capture in performance mode, simply run make in the top level. To build a version with stricter internal error checking assertions, run make assert . This version is still capable of operating at 10Gb/s on many systems, though will suffer marginal performance degradation, especially on slower CPUs. To build a debug version, run make debug . The debug build applies stricter warning checking requirements at build time, and enables detailed debug tracing throughout the application. This version is unlikely to keep up at high-rate.","title":"Building"},{"location":"install/#uninstallation","text":"To install Exact Capture, run make install as the root user. To uninstall, run make uninstall as the root user.","title":"(un)Installation"},{"location":"quick/","text":"To run Exact Capture on a single 10GbE interface, writing to a single disk slice, the following command line is sufficient: $ exact-capture --input=exanic0:0 --output=/data0/ --cpus=0:1:2 Note Canonical Linux interface names such as \u201ceth1\u201d or \u201cenp0s1\u201d can be freely used in place of Exablaze ExaNIC device names (e.g. \u201cexanic0:0\u201d). The interface must however be an ExaNIC. Note The CPU specification is a colon (\u201c:\u201d) separated list containing the management CPU, the ExaNIC listener thread CPU(s), and the ExaDisk writer thread CPU(s). It is assumed that CPU cores have been isolated according to the System Configuration instructions above. For more details see configuration options To run exact capture on a pair of 10GbE interfaces, writing to a two disk slices, using 5 cpu cores (management core = 0, NIC listener cores = 1,2, disk writer cores = 3,4): $ exact-capture --input=exanic0:0 --input=exanic0:1 --output=/data0/ --output=/data1/ --cpus=0:1,2:3,4","title":"Quick Start"},{"location":"server/","text":"You are free to run Exact Capture on any system hardware. The following table describes our recommendations for the minimum system hardware requirements. For general guidance, we have successfully run the system on suitably configured Dell R230 and R730 machines. Any of the Dell R 30 and R 40 machines are likely to be excellent candidates. CPUs Core Count The number of CPU cores required depends on: The number of interfaces that you wish to capture on The type and speed of the disk drives The maximum capture rate you need to sustain Assuming that ExaDisks are the target drives, each drive slice is capable of writing at a sustained rate of 10Gb/s. As an example, a minimal 10Gb/s Exact Capture installation will require 3 CPU cores. One core for a (hot) listener thread, one core for a (cold) disk writer thread and one management core. The management core is low priority and can be safely shared with other general purpose system cores. The listener thread should not be shared with any other process (i.e. be sure to make use of the isolcpus kernel parameter). In general, for n line-rate 10G ports, the system requires 2n + 1 CPU cores. e.g a 4x10G capture system will require 9 cores in total. Warning CPU core counts are based on actual cores, rather than hyperthreads. In general, we recommend disabling hyperthreads on CPUs that support them. Tip We have had good results with Intel Xeon E5-26xx range CPUs with a 3Ghz+ clock speed. For example the Intel Xeon E5-2643. Speed The minimum required CPU speed depends on the maximum capture rate required. For the purposes of this document, we assume that 10G line rate, at minimum sized (64B) frames is the capture rate requirement (i.e. approx. 14 million packets per second ). Tip We have found that 3Ghz+ CPUs are sufficient. RAM RAM usage will vary based on the number of NICs and disks that you are using. By default, each memory queue is organised into 256x 2MB slots for a total memory usage of approximately 512MB per queue. The total number of memory queues the product of the number of hot (ExaNIC) and cold (ExaDisk) threads. For a minimal 10Gb/s capture solution, with a single ExaNIC and ExaDisk, only 1 memory queue is required for a total of approximately 512MB of memory. For 4x10Gbs system, with 4 disks, 4x4 = 16 queues will be required, for a minimum memory usage of ~8GB. Tip We recommend at least 16GB of DDR IV RAM in your machine. PCIe For sustained, minimum sized packet capture, each 10Gb/s ExaNIC interface requires approximately 4x PCIe Gen 3 lanes. The hot threads must run on the CPU socket directly connected to these PCIe lanes. For sustained high performance writing, each ExaDisk interface requires 2x PCIe Gen 3 lanes. The cold threads must run on the CPU socket directly connected to these PCIe lanes. Tip For optimal performance, w recommend running PCIe Gen3x8 for all cards connected. ExaNIC All ExaNIC network cards will work with Exact Capture. Following is a summary of the features, requirements and limitations of each card: ExaNIC X10 / GM (2x 10GbE) - these cards can be used without restriction on suitable PCIe Gen 3x8 slots. Timestamp resolution is 6.2ns. ExaNIC HPT (2x 10GbE) - these cards can be used without restriction on suitable PCIe Gen 3x8 slots. Timestamp resolution is 0.25ns (250ps) ExaNIC X40 / VXP (8x 10GbE) - Only 2 ports can be used at line rate for all packet sizes. Up to 4 ports can be used at larger (average) packet sizes (e.g. 512B+). Timestamp resolution is 6.2ns. ExaNIC X40 (2x 40GbE) - Speeds up to 20Gb/s are likely to work out of the box on any single interface (though this is untested). Load balancing/packet spraying across multiple receive rings is also likely to assist line rate capture, though this is feature is not (yet) implemented. Tip ExaNIC X10 and ExaNIC HPT devices are currently optimal. Disk Drives Exact Capture is tested and optimized to run on ExaDisk FX1 NVMe SSD drives. Each ExaDisk is capable of running 40Gb/s sustained write speed to disk in a PCIe Gen 3x 8 slot. The drives are currently available in 4TB and 8TB capacities. The system will (in principle) operate with any disks. High speed flash drives, especially NVMe disks are highly recommended to keep the number of threads and memory usage down. For slower disks (e.g. SATA based flash disks) sharing CPU cores for writer threads is likely to reduce the CPU core count requirements without affecting overall performance. This is untested. Tip ExaDISK FX1 (8TB) is the recommended disk drive","title":"Server Requirements"},{"location":"server/#cpus","text":"","title":"CPUs"},{"location":"server/#ram","text":"RAM usage will vary based on the number of NICs and disks that you are using. By default, each memory queue is organised into 256x 2MB slots for a total memory usage of approximately 512MB per queue. The total number of memory queues the product of the number of hot (ExaNIC) and cold (ExaDisk) threads. For a minimal 10Gb/s capture solution, with a single ExaNIC and ExaDisk, only 1 memory queue is required for a total of approximately 512MB of memory. For 4x10Gbs system, with 4 disks, 4x4 = 16 queues will be required, for a minimum memory usage of ~8GB. Tip We recommend at least 16GB of DDR IV RAM in your machine.","title":"RAM"},{"location":"server/#pcie","text":"For sustained, minimum sized packet capture, each 10Gb/s ExaNIC interface requires approximately 4x PCIe Gen 3 lanes. The hot threads must run on the CPU socket directly connected to these PCIe lanes. For sustained high performance writing, each ExaDisk interface requires 2x PCIe Gen 3 lanes. The cold threads must run on the CPU socket directly connected to these PCIe lanes. Tip For optimal performance, w recommend running PCIe Gen3x8 for all cards connected.","title":"PCIe"},{"location":"server/#exanic","text":"All ExaNIC network cards will work with Exact Capture. Following is a summary of the features, requirements and limitations of each card: ExaNIC X10 / GM (2x 10GbE) - these cards can be used without restriction on suitable PCIe Gen 3x8 slots. Timestamp resolution is 6.2ns. ExaNIC HPT (2x 10GbE) - these cards can be used without restriction on suitable PCIe Gen 3x8 slots. Timestamp resolution is 0.25ns (250ps) ExaNIC X40 / VXP (8x 10GbE) - Only 2 ports can be used at line rate for all packet sizes. Up to 4 ports can be used at larger (average) packet sizes (e.g. 512B+). Timestamp resolution is 6.2ns. ExaNIC X40 (2x 40GbE) - Speeds up to 20Gb/s are likely to work out of the box on any single interface (though this is untested). Load balancing/packet spraying across multiple receive rings is also likely to assist line rate capture, though this is feature is not (yet) implemented. Tip ExaNIC X10 and ExaNIC HPT devices are currently optimal.","title":"ExaNIC"},{"location":"server/#disk-drives","text":"Exact Capture is tested and optimized to run on ExaDisk FX1 NVMe SSD drives. Each ExaDisk is capable of running 40Gb/s sustained write speed to disk in a PCIe Gen 3x 8 slot. The drives are currently available in 4TB and 8TB capacities. The system will (in principle) operate with any disks. High speed flash drives, especially NVMe disks are highly recommended to keep the number of threads and memory usage down. For slower disks (e.g. SATA based flash disks) sharing CPU cores for writer threads is likely to reduce the CPU core count requirements without affecting overall performance. This is untested. Tip ExaDISK FX1 (8TB) is the recommended disk drive","title":"Disk Drives"},{"location":"tuning/","text":"Performance Tuning Ensuring that the correct options and server settings ensures that exact-capture is running in an optimal manner. This document will detail a number of performance tuning techniques that can be used to improve the behaviour of exact-capture. Getting started The ExaNIC documentation covers a number of useful tuning techniques in order to ensure that ExaNICs are being used in an optimal manner. Many of these optimizations will also improve capture performance. The user should consult the following sections of the ExaNIC benchmarking guide before reading on: BIOS Configuration Kernel Build Configuration Kernel Boot Configuration Hardware Configuration NUMA systems On multi-socket systems, users should take care to ensure that capture hardware is local to a single socket. Pushing capture traffic over a CPU interconnect will lead to suboptimal capture performance, as traffic may be bottlenecked by this inter-CPU connection. The output of lspci can be used to determine the NUMA locality of installed hardware. On a server which has two ExaNICs and one ExaDisk installed, the NUMA locality can be quickly determined: [root@capture ~]# lspci -d 1ce4: -vvv |grep NUMA NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 The -d option when used with lspci allows the user to filter the devices displayed by vendor ID. Exablaze devices have the vendor ID 1ce4 and on this server where ExaDisks are in use, the NUMA node used by both the ExaNIC and ExaDisk can be queried in a single command. If ExaDisks are not in use, users should query lspci using the correct vendor ID for their own disks. Once the node of the installed hardware is known, the user should note which logical CPU cores are part of this node. This can be determined by the lspcu command: [root@capture ~]# lscpu |grep NUMA NUMA node(s): 2 NUMA node0 CPU(s): 0,2,4,6,8,10 NUMA node1 CPU(s): 1,3,5,7,9,11 On this system, the only cores that should be used for listen/write threads are 1,3,5,7,9,11 which are local to the same NUMA node as the hardware that will be used for packet capture. CPU configuration Ensuring that the user's CPU is correctly configured is vital to ensuring the performance of exact-capture. Any CPU cores that are used for listen/write threads should be configured as part of the Kernel Boot Configuration guide referenced earlier. These cores need to be specified in the isolcpus , nohz_full and rcu_nocbs parameters. Before starting exact-capture, ensure that the CPU cores to be used are not running in a power-saving state. One way to ensure the CPU is not running in a power-saving state before starting exact-capture is to cause all cores to (temporarily) spin on writing 0's to /dev/null/ : for cpu in {0..11} do taskset -c $cpu timeout 10 dd if=/dev/zero of=/dev/null & done After doing so, check the running frequency of the selected CPU cores (our CPU has a max frequency of 3.6Ghz, per the ouput of lscpu ): for cpu in /sys/devices/system/cpu/cpu*/cpufreq do cat $cpu/cpuinfo_cur_freq done 3601078 This confirms that all of the CPU cores on this server will run at their max frequency, before starting exact-capture. CPU core selection Exact-capture's --cpus option allows the user to select which CPU cores are allocated for management, listen and write threads (see the Configuration Guide and Internal Architecture for more information). The cores chosen for listen/write threads should be configured per the CPU configuration section. The core chosen for management does not need to be isolated, but it should not be shared with the cores used for listen/write threads. Interrupt configuration Both ExaNICs and capture disks can raise interrupts which can adversely impact the performance of exact-capture if the host is not configured appropriately. Servicing interrupts on cores used by listener threads is very disruptive to the performance of listener threads. When an interrupt is serviced by a core which is being used by a listener thread, the cached instructions belonging to the listener thread will be lost as the CPU fetches the instructions for the interrupt handler. That core will then execute the interrupt handler and finally return control to the listener thread (which will need to fetch it's instructions from memory all over again). To ensure that exact-capture can maintain losseless packet capture at high data rates, interrupts should not be serviced on cores used by listener threads. While exact capture is running, examine the output of cat /proc/interrupts to determine whether the which cores are servicing interrupts: [root@capture ~]# cat /proc/interrupts | grep -E 'CPU|exanic|nvme' CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 CPU8 CPU9 CPU10 CPU11 57: 50931 29339 0 0 0 40 0 0 0 0 0 0 PCI-MSI-edge nvme0q0, nvme0q1 59: 52418 29480 0 0 0 56 0 0 0 0 0 0 PCI-MSI-edge nvme1q0, nvme1q1 ... 116: 21370 33252 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge nvme4q7 117: 0 0 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge nvme4q8 143: 205804 16367 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge exanic0 145: 108387 15031 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge exanic1 Note the IRQ number in the leftmost column. On this server, CPU1 is still servicing interrupts for both NVMe storage drives and the ExaNICs (there may be other devices also raising interrupts on these cores). This will impede the performance of exact-capture, if listen threads are started on CPU0 or CPU1. Interrupt steering can be configured by setting smp_affinity correctly in procfs. smp_affinity is a bitmask which determines which CPUs can be used to service a given IRQ number, where the least significant bit corresponds to CPU0. First, force all interrupts to be serviced by CPU0: echo 1 > /proc/irq/default_smp_affinity for i in $(ls /proc/irq/); do echo 1 > /proc/irq/$i/smp_affinity ; done Next, allow any CPU cores not used by listener cores to service interrupts generated by the capture disks. For this server, CPU0 is used for management, CPU1 and CPU3 are used for listener threads and CPU5, CPU7, CPU9 and CPU11 are used for writer threads: ./bin/exact-capture --cpus 0:1,3:5,7,9,11 ... In this case, the correct value for the smp_affinity bitmask is 111111110101 , or FF5 . This will mask off CPU1 and CPU3 and allow interrupts to capture disks to be serviced on any core. The correct IRQ numbers can be determined from the output of cat /proc/interrupts as above. In this case, the capture disks have IRQ numbers 57-117. With this in mind, setting the smp_affinity for each IRQ number can be achieved by the following command: for i in {57..117}; do echo FF5 > /proc/irq/$i/smp_affinity ; done The kernel documentation for IRQ affinity offers a detailed guide for configuring smp_affinity values. Note It is recommended to disable interrupt generation completely for ExaNICs which are solely used for packet capture. This can be achieved by enabling Bypass-only mode , which can be automatically enabled by exact-capture by supplying the --no-kernel option. Troubleshooting The --perf-test option offers a number of utilities useful for diagnosing performance bottlenecks in a given system. These options can be combined with the --verbose and --more-verbose 2 to assess whether a server has been optimally configured. Check the Configuration Guide for the list of supported performance testing options. For example, the --perf-test 3 can be used to evaluate the write performance of a given system: ./bin/exact-capture -i exanic0:0 -i exanic0:1 -o /mnt/exadisk0/test0 -o /mnt/exadisk1/test1 -o /mnt/exadisk2/test2 -o /mnt/exadisk3/test3 -c 0:1,3:5,7,9,11 -k -v -V 2 -p 2 ... [20200908T112533.543]: Listener:00 exanic0:0 (0.0) -- 0.00Gbps 0.00Mpps (HW:0.00iMpps) 0.00MB 0 Pkts (HW:0 Pkts) [lost?:0] (4569.582M Spins1 0.000M SpinsP ) 0errs 0drp 0swofl 0hwofl [20200908T112533.543]: Listener:01 exanic0:1 (0.1) -- 0.00Gbps 0.00Mpps (HW:0.00iMpps) 0.00MB 40 Pkts (HW:40 Pkts) [lost?:0] (4562.232M Spins1 0.000M SpinsP ) 0errs 0drp 0swofl 0hwofl [20200908T112533.543]: Total - All Listeners -- 0.00Gbps 0.00Mpps (HW:0.00iMpps) 0.00MB 40 Pkts (HW:40 Pkts) [lost?:0] (9131.814M Spins1 0.000M SpinsP ) 0errs 0drp 0swofl 0hwofl [20200908T112533.543]: Writer:00 .t/exadisk0/test0 -- 6.55Gbps (6.55Gbps wire 9.82Gbps disk) 12.79Mpps 16212.34MB (16212.34MB 24320.00MB) 265623040 Pkts 0.000M Spins [20200908T112533.543]: Writer:01 .t/exadisk0/test0 -- 5.41Gbps (5.41Gbps wire 8.12Gbps disk) 10.57Mpps 13397.85MB (13397.85MB 20098.00MB) 219510356 Pkts 0.000M Spins [20200908T112533.543]: Writer:02 .t/exadisk0/test0 -- 6.00Gbps (6.00Gbps wire 9.00Gbps disk) 11.72Mpps 14851.09MB (14851.09MB 22278.00MB) 243320316 Pkts 0.000M Spins [20200908T112533.543]: Writer:03 .t/exadisk0/test0 -- 6.05Gbps (6.05Gbps wire 9.08Gbps disk) 11.83Mpps 14989.75MB (14989.75MB 22486.00MB) 245592092 Pkts 0.000M Spins [20200908T112533.543]: Total - All Writers -- 24.01Gbps (24.01Gbps wire 36.02Gbps disk) 46.90Mpps 59451.04MB (59451.04MB 89182.00MB) 974045804 Pkts 0.000M Spins Exact Capture finished HW Received: 40 packets ( 0.000 MP/s ) SW Received: 40 packets ( 0.000 MP/s ) 0 MB ( 0.000 Gb/s ) SW Wrote: 974045804 packets ( 46.902 MP/s ) 59451 MB ( 24.014 Gb/s ) Lost HW/SW (?): 0 packets ( 0.000 MP/s ) Lost RX/WR: 0 packets ( 0.000 MP/s ) 0 MB ( 0.000 Gb/s ) Dropped: 0 packets ( 0.000 MP/s ) SW Overflows: 0 times ( 0.000 /s ) We can observe that this system is capable of writing ~36.02Gbps to the disks specified.","title":"Performance Tuning"},{"location":"tuning/#performance-tuning","text":"Ensuring that the correct options and server settings ensures that exact-capture is running in an optimal manner. This document will detail a number of performance tuning techniques that can be used to improve the behaviour of exact-capture.","title":"Performance Tuning"},{"location":"tuning/#getting-started","text":"The ExaNIC documentation covers a number of useful tuning techniques in order to ensure that ExaNICs are being used in an optimal manner. Many of these optimizations will also improve capture performance. The user should consult the following sections of the ExaNIC benchmarking guide before reading on: BIOS Configuration Kernel Build Configuration Kernel Boot Configuration Hardware Configuration","title":"Getting started"},{"location":"tuning/#numa-systems","text":"On multi-socket systems, users should take care to ensure that capture hardware is local to a single socket. Pushing capture traffic over a CPU interconnect will lead to suboptimal capture performance, as traffic may be bottlenecked by this inter-CPU connection. The output of lspci can be used to determine the NUMA locality of installed hardware. On a server which has two ExaNICs and one ExaDisk installed, the NUMA locality can be quickly determined: [root@capture ~]# lspci -d 1ce4: -vvv |grep NUMA NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 NUMA node: 1 The -d option when used with lspci allows the user to filter the devices displayed by vendor ID. Exablaze devices have the vendor ID 1ce4 and on this server where ExaDisks are in use, the NUMA node used by both the ExaNIC and ExaDisk can be queried in a single command. If ExaDisks are not in use, users should query lspci using the correct vendor ID for their own disks. Once the node of the installed hardware is known, the user should note which logical CPU cores are part of this node. This can be determined by the lspcu command: [root@capture ~]# lscpu |grep NUMA NUMA node(s): 2 NUMA node0 CPU(s): 0,2,4,6,8,10 NUMA node1 CPU(s): 1,3,5,7,9,11 On this system, the only cores that should be used for listen/write threads are 1,3,5,7,9,11 which are local to the same NUMA node as the hardware that will be used for packet capture.","title":"NUMA systems"},{"location":"tuning/#cpu-configuration","text":"Ensuring that the user's CPU is correctly configured is vital to ensuring the performance of exact-capture. Any CPU cores that are used for listen/write threads should be configured as part of the Kernel Boot Configuration guide referenced earlier. These cores need to be specified in the isolcpus , nohz_full and rcu_nocbs parameters. Before starting exact-capture, ensure that the CPU cores to be used are not running in a power-saving state. One way to ensure the CPU is not running in a power-saving state before starting exact-capture is to cause all cores to (temporarily) spin on writing 0's to /dev/null/ : for cpu in {0..11} do taskset -c $cpu timeout 10 dd if=/dev/zero of=/dev/null & done After doing so, check the running frequency of the selected CPU cores (our CPU has a max frequency of 3.6Ghz, per the ouput of lscpu ): for cpu in /sys/devices/system/cpu/cpu*/cpufreq do cat $cpu/cpuinfo_cur_freq done 3601078 This confirms that all of the CPU cores on this server will run at their max frequency, before starting exact-capture.","title":"CPU configuration"},{"location":"tuning/#cpu-core-selection","text":"Exact-capture's --cpus option allows the user to select which CPU cores are allocated for management, listen and write threads (see the Configuration Guide and Internal Architecture for more information). The cores chosen for listen/write threads should be configured per the CPU configuration section. The core chosen for management does not need to be isolated, but it should not be shared with the cores used for listen/write threads.","title":"CPU core selection"},{"location":"tuning/#interrupt-configuration","text":"Both ExaNICs and capture disks can raise interrupts which can adversely impact the performance of exact-capture if the host is not configured appropriately. Servicing interrupts on cores used by listener threads is very disruptive to the performance of listener threads. When an interrupt is serviced by a core which is being used by a listener thread, the cached instructions belonging to the listener thread will be lost as the CPU fetches the instructions for the interrupt handler. That core will then execute the interrupt handler and finally return control to the listener thread (which will need to fetch it's instructions from memory all over again). To ensure that exact-capture can maintain losseless packet capture at high data rates, interrupts should not be serviced on cores used by listener threads. While exact capture is running, examine the output of cat /proc/interrupts to determine whether the which cores are servicing interrupts: [root@capture ~]# cat /proc/interrupts | grep -E 'CPU|exanic|nvme' CPU0 CPU1 CPU2 CPU3 CPU4 CPU5 CPU6 CPU7 CPU8 CPU9 CPU10 CPU11 57: 50931 29339 0 0 0 40 0 0 0 0 0 0 PCI-MSI-edge nvme0q0, nvme0q1 59: 52418 29480 0 0 0 56 0 0 0 0 0 0 PCI-MSI-edge nvme1q0, nvme1q1 ... 116: 21370 33252 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge nvme4q7 117: 0 0 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge nvme4q8 143: 205804 16367 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge exanic0 145: 108387 15031 0 0 0 0 0 0 0 0 0 0 PCI-MSI-edge exanic1 Note the IRQ number in the leftmost column. On this server, CPU1 is still servicing interrupts for both NVMe storage drives and the ExaNICs (there may be other devices also raising interrupts on these cores). This will impede the performance of exact-capture, if listen threads are started on CPU0 or CPU1. Interrupt steering can be configured by setting smp_affinity correctly in procfs. smp_affinity is a bitmask which determines which CPUs can be used to service a given IRQ number, where the least significant bit corresponds to CPU0. First, force all interrupts to be serviced by CPU0: echo 1 > /proc/irq/default_smp_affinity for i in $(ls /proc/irq/); do echo 1 > /proc/irq/$i/smp_affinity ; done Next, allow any CPU cores not used by listener cores to service interrupts generated by the capture disks. For this server, CPU0 is used for management, CPU1 and CPU3 are used for listener threads and CPU5, CPU7, CPU9 and CPU11 are used for writer threads: ./bin/exact-capture --cpus 0:1,3:5,7,9,11 ... In this case, the correct value for the smp_affinity bitmask is 111111110101 , or FF5 . This will mask off CPU1 and CPU3 and allow interrupts to capture disks to be serviced on any core. The correct IRQ numbers can be determined from the output of cat /proc/interrupts as above. In this case, the capture disks have IRQ numbers 57-117. With this in mind, setting the smp_affinity for each IRQ number can be achieved by the following command: for i in {57..117}; do echo FF5 > /proc/irq/$i/smp_affinity ; done The kernel documentation for IRQ affinity offers a detailed guide for configuring smp_affinity values. Note It is recommended to disable interrupt generation completely for ExaNICs which are solely used for packet capture. This can be achieved by enabling Bypass-only mode , which can be automatically enabled by exact-capture by supplying the --no-kernel option.","title":"Interrupt configuration"},{"location":"tuning/#troubleshooting","text":"The --perf-test option offers a number of utilities useful for diagnosing performance bottlenecks in a given system. These options can be combined with the --verbose and --more-verbose 2 to assess whether a server has been optimally configured. Check the Configuration Guide for the list of supported performance testing options. For example, the --perf-test 3 can be used to evaluate the write performance of a given system: ./bin/exact-capture -i exanic0:0 -i exanic0:1 -o /mnt/exadisk0/test0 -o /mnt/exadisk1/test1 -o /mnt/exadisk2/test2 -o /mnt/exadisk3/test3 -c 0:1,3:5,7,9,11 -k -v -V 2 -p 2 ... [20200908T112533.543]: Listener:00 exanic0:0 (0.0) -- 0.00Gbps 0.00Mpps (HW:0.00iMpps) 0.00MB 0 Pkts (HW:0 Pkts) [lost?:0] (4569.582M Spins1 0.000M SpinsP ) 0errs 0drp 0swofl 0hwofl [20200908T112533.543]: Listener:01 exanic0:1 (0.1) -- 0.00Gbps 0.00Mpps (HW:0.00iMpps) 0.00MB 40 Pkts (HW:40 Pkts) [lost?:0] (4562.232M Spins1 0.000M SpinsP ) 0errs 0drp 0swofl 0hwofl [20200908T112533.543]: Total - All Listeners -- 0.00Gbps 0.00Mpps (HW:0.00iMpps) 0.00MB 40 Pkts (HW:40 Pkts) [lost?:0] (9131.814M Spins1 0.000M SpinsP ) 0errs 0drp 0swofl 0hwofl [20200908T112533.543]: Writer:00 .t/exadisk0/test0 -- 6.55Gbps (6.55Gbps wire 9.82Gbps disk) 12.79Mpps 16212.34MB (16212.34MB 24320.00MB) 265623040 Pkts 0.000M Spins [20200908T112533.543]: Writer:01 .t/exadisk0/test0 -- 5.41Gbps (5.41Gbps wire 8.12Gbps disk) 10.57Mpps 13397.85MB (13397.85MB 20098.00MB) 219510356 Pkts 0.000M Spins [20200908T112533.543]: Writer:02 .t/exadisk0/test0 -- 6.00Gbps (6.00Gbps wire 9.00Gbps disk) 11.72Mpps 14851.09MB (14851.09MB 22278.00MB) 243320316 Pkts 0.000M Spins [20200908T112533.543]: Writer:03 .t/exadisk0/test0 -- 6.05Gbps (6.05Gbps wire 9.08Gbps disk) 11.83Mpps 14989.75MB (14989.75MB 22486.00MB) 245592092 Pkts 0.000M Spins [20200908T112533.543]: Total - All Writers -- 24.01Gbps (24.01Gbps wire 36.02Gbps disk) 46.90Mpps 59451.04MB (59451.04MB 89182.00MB) 974045804 Pkts 0.000M Spins Exact Capture finished HW Received: 40 packets ( 0.000 MP/s ) SW Received: 40 packets ( 0.000 MP/s ) 0 MB ( 0.000 Gb/s ) SW Wrote: 974045804 packets ( 46.902 MP/s ) 59451 MB ( 24.014 Gb/s ) Lost HW/SW (?): 0 packets ( 0.000 MP/s ) Lost RX/WR: 0 packets ( 0.000 MP/s ) 0 MB ( 0.000 Gb/s ) Dropped: 0 packets ( 0.000 MP/s ) SW Overflows: 0 times ( 0.000 /s ) We can observe that this system is capable of writing ~36.02Gbps to the disks specified.","title":"Troubleshooting"},{"location":"utils/","text":"Exact Capture is supplied with a small collection of tools for operating on expcap files. These are: exact-pcap-extract - This tool has two purposes. Firstly, it is used to extract all packets associated with a given port and device number from a collection of expcap files. Secondly, it can be used to convert from expcap format into standard pcap format. exact-pcap-parse - This tool is useful for creating ASCII text dumps of pcap and expcap files and for working with picosecond timestamps. exact-pcap-match - A common use case of is for Exact Capture is latency calculations. This tool can be used to match identical frames from two pcap or expcap files and calculate the latency between them. It can be easily extended to support matching frames that are not identical (e.g. tick-to-trade latency calculations). (edited)","title":"Tools & Utlities"},{"location":"versions/","text":"Version 1.1 Release date: 30 September 2019 Commit ID: 5d337a645987af00fc0d1afa6769ee7ccf62caea Source: https://github.com/exablaze-oss/exact-capture/tree/v1.1 Release Notes: Moved documentation online use mkdocs and github pages Removed PDF documentation Updated readme Version 1.0 Release date: 7 March 2018 Commit ID: 624a3f97bbaddd3cf827387e2352d5f5c662a7e5 Source: https://github.com/exablaze-oss/exact-capture/tree/v1.0 Release Notes: Initial release of Exact Capture PDF documentation included in repo","title":"Version History"},{"location":"versions/#version-11","text":"Release date: 30 September 2019 Commit ID: 5d337a645987af00fc0d1afa6769ee7ccf62caea Source: https://github.com/exablaze-oss/exact-capture/tree/v1.1 Release Notes: Moved documentation online use mkdocs and github pages Removed PDF documentation Updated readme","title":"Version 1.1"},{"location":"versions/#version-10","text":"Release date: 7 March 2018 Commit ID: 624a3f97bbaddd3cf827387e2352d5f5c662a7e5 Source: https://github.com/exablaze-oss/exact-capture/tree/v1.0 Release Notes: Initial release of Exact Capture PDF documentation included in repo","title":"Version 1.0"}]}